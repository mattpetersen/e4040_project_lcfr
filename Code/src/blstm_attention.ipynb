{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLSTM + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520 (CNMeM is disabled, cuDNN Version is too old. Update to v5, was 3007.)\n",
      "/home/ubuntu/miniconda2/envs/theano/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose: True\n",
      "normal: True\n",
      "nhidden2: 300\n",
      "win: 3\n",
      "savemodel: False\n",
      "seed: 345\n",
      "emb_dimension: 90\n",
      "nepochs: 20\n",
      "minibatch_size: 4978\n",
      "nhidden: 300\n",
      "decay: True\n",
      "lr: 0.025\n",
      "folder: ../result_ma3\n",
      "... loading the dataset\n",
      "Sentences in train: 4978, Words in train: 56590\n",
      "Sentences in test: 893, Words in test: 9198\n",
      "... building the model\n",
      "... training\n",
      "NEW BEST: epoch 0, minibatch 1/1, best test F1: 86.110\n",
      "NEW BEST: epoch 1, minibatch 1/1, best test F1: 90.530\n",
      "NEW BEST: epoch 2, minibatch 1/1, best test F1: 92.370\n",
      "NEW BEST: epoch 3, minibatch 1/1, best test F1: 92.830\n",
      "NEW BEST: epoch 4, minibatch 1/1, best test F1: 93.540\n",
      "\n",
      "\n",
      "\n",
      "NEW BEST: epoch 8, minibatch 1/1, best test F1: 93.560\n",
      "NEW BEST: epoch 9, minibatch 1/1, best test F1: 93.940\n",
      "\n",
      "\n",
      "\n",
      "NEW BEST: epoch 13, minibatch 1/1, best test F1: 94.260\n",
      "\n",
      "NEW BEST: epoch 15, minibatch 1/1, best test F1: 94.350\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('BEST RESULT: epoch', 15, 'best test F1', 94.35, 'with the model', '../result_ma3')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"We have tried to implement Bidirectional LSTM with attention mechanisim to see how it is going to perform.\n",
    "Here we pass our sequence once from start to end and once from end tostart whose reults h_1 and h_2 we sum at the end \n",
    "before we send it to decoding phase. BLSTM were supposed to give better results because of their ability to pass in \n",
    "reversed order and get more information about dependencies. However, since more passes and weights introduced for this\n",
    "experiments one epoch was taking around 1 hour and so we could not run it for more than 20 epochs. In general, it could\n",
    "overfit because of increased complexity and we might want to use dropout in appropriate fashion. All in all, even though\n",
    "we were aiming to surpass 95.5 with BLSTM + Attention, we could only reach 94.35 with 20 epochs.\n",
    "\"\"\"\n",
    "import blstm_with_attention\n",
    "import imp\n",
    "imp.reload(blstm_with_attention)\n",
    "\n",
    "param = {\n",
    "    'lr': 0.025,\n",
    "    'verbose': True,\n",
    "    'decay': True,\n",
    "    'win': 3,\n",
    "    'nhidden': 300,\n",
    "    'nhidden2':300,\n",
    "    'seed': 345,\n",
    "    'emb_dimension': 90,\n",
    "    'nepochs': 20,\n",
    "    'savemodel': False,\n",
    "    'normal': True,\n",
    "    'minibatch_size':4978,\n",
    "    'folder':'../result_ma3'}\n",
    "\n",
    "blstm_with_attention.test_blstm_att(**param);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
